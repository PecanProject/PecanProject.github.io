---
title: 'GSoC 2025 - PEcAn Project Ideas'
---

# GSoC - PEcAn Project Ideas{#background}

PEcAn is an open-source ecosystem modeling framework integrating data, models, and uncertainty quantification. Below is a list of potential ideas where contributors can help improve and expand PEcAn. To get started contributing to PEcAn, check out [this guide](https://github.com/PecanProject/pecan/discussions/3469). Come find us on Slack to discuss. If you have questions or would like to propose your own idea, contact @kooper in or join our **[#gsoc-2025](https://pecanproject.slack.com/archives/C0853U6GF71)** channel in Slack!

---

## Project Ideas{#ideas}

Below is a list of project ideas. Feel free to contact the listed mentors on Slack to discuss further or contact @kooper with new ideas and he can help connect you with mentors.

1. [Global Sensitivity Analysis / Uncertainty Partitioning](#sa)  
2. [Parallelization of Model Runs on HPC](#hpc)  
3. [Database and Data Improvements](#db)  
4. [Development of Notebook-based PEcAn Workflows](#notebook)  
5. [Refactoring Compile-time Flags to Runtime Flags in SIPNET](#sipnet) 

---

### 1. Global Sensitivity Analysis / Uncertainty Partitioning{#sa}

This project would extend PEcAn's existing uncertainty partitioning routines, which are primarily one-at-a-time and focused on model parameters, to also consider ensemble-based uncertainties in other model inputs (meteorology, soils, vegetation, phenology, etc). This project would employ Sobol' methods and some uncommitted code exists that manually prototyped how this would be done in PEcAn. The goal would be to refactor/reimplement this prototype into a reliable, automated system and apply it to some key test cases in both natural and managed ecosystems.


**Expected outcomes:**

A successful project would complete the following tasks:

* Reliable, automated Sobol sensitivity analyss and uncertainty partitioning across multiple model inputs.
* Applications to test case(s) in natural and / or managed ecosystems.

**Prerequisites:**

- Required: R (existing workflow and prototype is in R)
- Helpful: familiarity with sensitivity analyses

**Contact person:**

Mike @Dietze

**Duration:**

Flexible to work as either a Medium (175hr) or Large (350 hr)

**Difficulty:**

Medium

---

### 2. Parallelization of Model Runs on HPC{#hpc}

This project would extend PEcAn's existing run mechanisms to be able to run on a High Performance Compute cluster (HPC) using [Apptainer](https://apptainer.org). For uncertaintity analysis, PEcAn will run the same model 1000s of times with small permutations. This is a perfect use for an HPC run. The goal is to not submit 1000s of jobs, but have a single job with multiple nodes that will run all of the ensembles efficiently. Running can be orchistrated using RabbitMQ, but other methods are also encouraged. The end goal should be for the PEcAn system to be launched, and run the full workflow on the HPC from start to finish leveraging as many nodes as it is given during the submission.

**Expected outcomes:**

A successful project would complete the following tasks:

* Show different ways to launch jobs (rabbitmq, lock files, simple round robin, etc)
* Report of different options and how they can be enabled.

**Prerequisites:**

- Required: R (existing workflow and prototype is in R), Docker
- Helpful: Familiarity with HPC and Apptainer

**Contact person:**

Rob @Kooper

**Duration:**

Flexible to work as either a Medium (175hr) or Large (350 hr)

**Difficulty:**

Medium

---
### 3. Database and Data Improvements{#db}

PEcAn relies on the BETYdb database to store trait and yield data as well as model provenance information. This project aims to separate trait data from provenance tracking, ensure that PEcAn is able to run without the server currently required to run the Postgres database used by BETYdb, and enable flexible data sharing in place of a server-reliant sync mechanism. The goal is to make PEcAn workflows easier to test, deploy, and use while also making data more accessible.


**Potential Directions**

- **Minimal BETYdb Database:** Create a simplified version of BETYdb for demonstrations and Integration tests, which might include:
   - Review the provenance information we currently log, identify components that no longer need to be tracked or that should be temporary rather than permanent records, and build tools to clean unneeded records from the database.
   - Design and create a freestanding version of the trait data, including choosing the format and distribution method, implementing whatever pipelines are needed to move the data over, and documenting how to use and update the result.
   - Review the information we currently log, identify components that no longer need to be tracked or that should be temporary rather than permanent, and build tools to clean unneeded/expired records from the database.

- **Non-Database Setup:** Enable workflows that do not require PostgreSQL or a web front-end, potentially including:
   - Identify PEcAn modules that are still DB-dependent and refactor them to allow freestanding use
   - Implement mechanisms for decoupling the DB from the model pipelines in time and space while still tracking provenance. Perhaps this could involve separate prep/execution/post-logging phases, but we encourage your creative suggestions.
   - Create tools that maximize interoperability with data from other sources, including from external databases or the user's own observations.
   - Identify functionality from the "BETYdb network" sync system that is out of date and replace or remove it as needed.

**Expected outcomes**:

A successful project would complete a subset of the following tasks:
- A lightweight, distributable demo Postgres database.
- A distributable dataset of the existing trait and yield records in a maximally reusable format (i.e. maybe _not_ Postgres)
- A workflow that is independent of the Postgres database.

**Skills Required**:

- Familiarity with database concepts required
- Postgres experience helpful (and required if proposing DB cleanup tasks)
- R experience helpful (and required if proposing PEcAn code changes)

**Contact person:**

Chris Black (@infotroph)

**Duration:**

Suitable for a Medium (175hr) or Large (350 hr) project.

**Difficulty:**

Intermediate to hard


---

### 4. Development of Notebook-based PEcAn Workflows{#notebook}

The PEcAn workflow is currently run using either a web based user interface, an API, or custom R scripts. The web based user interface is easiest to use, but has limited functionality whereas the custom R scripts and API are more flexible, but require more experience.

This project will focus on building Quarto notebooks that provide an interface to PEcAn that is both welcoming to new users and flexible enough to be a starting point for more advanced users. It will build on existing [Pull Request 1733](https://github.com/PecanProject/pecan/pull/1733).

**Expected outcomes:**

- Two or more template workflows for running the PEcAn workflow. 
- Written vignette and video tutorial introducing their use.

**Prerequisites:**

- Familiarity with R. 
- Familiarity with R studio and Quarto or Rmarkdown is a plus.

**Contact person:**
David LeBauer @dlebauer, Nihar Sanda @koolgax99

**Duration:**
Medium (175hr)

**Difficulty:**
Medium


### 5. Refactoring Compile-time Flags to Runtime Flags in SIPNET{#sipnet}

**Project Overview**

The ecosystem SIPNET is a core component of many PEcAn analyses. SIPNET is compiled with multiple compile-time flags that control whether different features are turned on and off. Thus, as currently configured, each model structure requires a separate compiled binary. 

This project will refactor these flags to be runtime-configurable via command-line arguments or a configuration file, improving usability and testing efficiency.

**Expected Outcomes**

- Convert selected SIPNET compile-time flags to runtime options.
- Develop a global configuration object for managing runtime flags.
- Improve testability by enabling different configurations without recompiling.

**Prerequisites**

- Required: C, experience with compilers and build systems.
- Helpful: Understanding of simulation models.

**Mentor(s)**

- David LeBauer (@dlebauer)
- Mike Longfritz

**Duration**
- Medium (175hr) or Large (350hr)

**Difficulty**
- Medium to Hard


<!--


# This comment section for ideas that may be potentially viable in future (with revision)


#### BETYdb R data package

BETYdb's web front end is built on a version of Ruby on Rails that is functional byt no longer supported. A key feature of BETYdb is that the data is open and accessible. 

Building an R data package would make the Trait and Yield data currently in BETYdb more accessible to users beyond the PEcAn community.

**Expected outcomes:**

A successful project would complete a subset of the following tasks:

- An R package containing the data currently hosted in BETYdb.
- Documentation and examples of use.
- Updates to BETYdb documentation.

**Prerequisites:**

- Required: R
- Helpful: R package development; familiarity with relational databases and SQL.

**Contact person:**

David LeBauer (@dlebauer)

**Duration:**

Medium (175hr) to Large (350hr) depending on scope of proposal.

**Difficulty:**

Medium

---

#### [Optimize PEcAn for freestanding use of single packages [R package development]](#freestanding)

PEcAn was designed as a system of independent modules, each implemented as its own R package that was intended to be usable either standalone or as part of the full PEcAn system. Subsequent development focused on the most common cross-module workflows has lead to tighter coupling between modules than was originally intended, so that in practice many of the modules are now challenging to use, test, or develop without a full understanding of their interdependencies. Further, some packages expect inputs and outputs in data structures that are only generated by other PEcAn packages but might be more easily provided in standard well-known formats. We seek proposals to re-loosen these couplings by revisiting the design and interface of PEcAn packages through one or more of:

1. Refactoring code to remove unneeded dependencies, simplify package interfaces, and exchange data in standard formats
2. Identifying exported functions that are not core to the functionality of the package, and removing them or making them internal
3. Writing tests and examples that demonstrate freestanding use of the package
4. Developing methods for tracking the dependencies between packages that cannot be eliminated, including how these change between package versions
   Proposals for this project should choose a subset of these approaches and apply them to a specified subset of the PEcAn packages. Strong proposals will clearly show why each chosen package should be a priority, how it will become more independent at the completion of the project, and what interface changes will be needed to achieve this.

**Expected outcome:**

- One or more PEcAn packages can be installed, used, and/or tested without the user needing to know [something previously important] about [another package].

**Prerequisites:**

- Familiarity with R, especially how it manages dependencies between packages, and with concepts of software package development. Helpful resources: [rOpenSci packages](https://devguide.ropensci.org/index.html) and [R packages](https://r-pkgs.org). Experience with multi-package code bases will be very helpful.

**Contact person:**
Chris Black @infotroph, Shashank Singh @moki1202

**Duration:**
Flexible to work as either a Small (175hr) or Large (350 hr)

**Difficulty:**
Medium, Large
---

#### [PEcAn model coupling and development [Data Science]](#coupling)

PEcAn has the capability to interface multiple ecological models. The goal of this project is to improve the coupling of existing models to PEcAn (specifically FATES) and add new models (specifically a simple vegetation model that is under development). It is also possible to contribute to the development of the simple vegetation model which is written in Fortran.

**Expected outcome:**

- New or improved PEcAn model packages.

**Prerequisites:**

- R, Fortran is an advantage.

**Contact person:**
Hui Tang @Hui Tang, Istem Fer @istfer

**Duration:**
Flexible to work as either a Small (175hr) or Large (350 hr)

**Difficulty:**
Medium

---
-->

